---
title: "Report methodology step-by-step"
output:
  html_document:
    toc: yes
    toc_float: yes
    fig-width: 10
---
```{r}
#| label: chunk setup
#| include: FALSE
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  fig.path = "figures/"
)
```
```{r}
#| label: source config
#| include: FALSE
#| results: 'hide'
#| warning: FALSE
#| message: FALSE

library(here)

here::i_am("R/reports/reporn_methods_workflow/report_methodology_workflow.qmd")

# Load configuration
source(
  here::here(
    "R/00_Config_file.R"
  )
)

invisible(
  lapply(
    list.files(
      path = here::here("R/functions"),
      pattern = "*.R",
      recursive = TRUE,
      full.names = TRUE
    ),
    source
  )
)
```
```{r}
#| label: chunk theme
#| include: FALSE
ggplot2::theme_set(
  ggplot2::theme_bw() +
    ggplot2::theme(
      axis.title = ggplot2::element_text(size = 25),
      axis.text = ggplot2::element_text(size = 15),
      strip.text = ggplot2::element_text(size = 15),
      panel.grid = ggplot2::element_blank()
    )
)

# simple templete to simplyfy ploting temporal figures
plot_template_temporal <-
  tibble::tibble() %>%
  ggplot2::ggplot(
    aes(x = age)
  ) +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    x = "age (cal yr BP)"
  )

fig_width_def <- 60 # this is used to wrap text.

#' @description
#' A helper function to colour the facets
color_facets <-
  function(sel_plot,
           sel_palette,
           direction = c("vertical", "horizontal"),
           return_raw = FALSE) {
    direction <- match.arg(direction)
    g <-
      ggplot2::ggplot_gtable(
        ggplot2::ggplot_build(sel_plot)
      )
    stripr <-
      which(grepl("strip-t", g$layout$name))

    for (i in seq_along(stripr)) {
      obejct_val <-
        sort(stripr,
          decreasing = ifelse(direction == "vertical",
            TRUE,
            FALSE
          )
        )[i]

      j <-
        which(grepl("rect", g$grobs[[obejct_val]]$grobs[[1]]$childrenOrder))

      g$grobs[[obejct_val]]$grobs[[1]]$children[[j]]$gp$fill <-
        sel_palette[i]
    }

    if (
      return_raw == TRUE
    ) {
      return(g)
    } else {
      grid::grid.draw(g)
    }
  }
```

The objective of this report is to give an detailed description of individual steps of the data analysis

# Pollen data aquisition

## FOSSILPOL

The compilation of a pollen dataset for our analysis is performed a priori.
Raw pollen datasets are carefully selected with the *R-Fossilpol* package, and the guidelines to the workflow are well described in Flantua et al. 2023 and in our website [Fossilpol project](https://hope-uib-bio.github.io/FOSSILPOL-website/about.html). Most datasets are obtained from the [Neotoma Paleoecology Database](https://www.neotomadb.org). Some additional data are from private owners in areas with data gaps, which we have limited access to use. We do not have the intellectual property rights to make these data public available. Therefore, only the derivatives of the analysis can be publicly shared. Table 1 provides a summary of the settings used in the FOSSILPOL workflow to obtain a standardised project dataset. This input data are further filter during the data processing steps in HOPE to get the final collection of a standardized dataset of high data quality we can use further in our data analyses.  

### Harmonisation tables

An important step in FOSSILPOL to obtain a standardised pollen data set within and across regions is the harmonisation of pollen types. Different analysts have different backgrounds and schools using different nomenclature, and the level of pollen taxonomic identifications and names can vary widely. To be able to make numerical comparisons of different pollen records, the level of pollen taxonomy should be similar. Consequently, pollen harmonisation tables have been produced for different regions to try to minimise biases related to this. The regional harmonisation tables created in our project are for Europe, Levant, Siberia, Southern Asia, Northern America, Latin America, and the Indo-Pacific region (Birks et al. harmonisation paper). These tables are used as input in the Fossilpol workflow above ([see Fossilpol step_by_step guide](https://hope-uib-bio.github.io/FOSSILPOL-website/step_by_step_guide.html)).
<br>

### Data pollen assembly

We have applied a number of filtering criteria to obtain as high a data quality as possible so that we can compare the numerical estimates on standardised data sets. These filtering criteria are: remove potentially duplicated pollen records, sorting levels (samples) by age, remove levels (samples) lower than a threshold of total number pollen grains counted (= pollen sum), remove pollen records based on age (minimum and maximum age ranges), remove levels (samples) depending on the age of the last control point, remove samples beyond the age ranges of interest, and remove pollen records if the total number of samples (N) is too low.

This filtering is done on the chronologies, raw pollen counts, harmonised pollen counts, and the age uncertainties from the age-depth models (Bchron). The preferable number of minimum pollen grains is set to 150, but this led to a great loss of datasets in regions with less data coverage, and we therefore reduced this number to 25 with the condition that less than 50 % of the samples must have a low pollen sum. This allow us to keep more datasets, but in the cases pollen records have a low minimum pollen sum, we acknowledge that the estimates of pollen assemblage properties (PAPs) are less robust. The maximum age beyond extrapolation is set to 3000 years because ages extrapolated beyond this threshold is considered highly uncertain. Finally, pollen records with less than 5 samples are removed for further analyses. 

```{r}
#| label: load data pollen
data_pollen <-
  targets::tar_read(
    name = data_assembly_filtered,
    store = external_storage_targets
  ) %>%
  dplyr::select(
    dataset_id,
    levels,
    counts_harmonised
  )

data_meta <-
  targets::tar_read(
    name = "data_meta",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  ) %>%
  dplyr::mutate(
    sel_classification = dplyr::case_when(
      ecozone_koppen_15 == "Cold_Without_dry_season" ~ ecozone_koppen_30,
      ecozone_koppen_5 == "Cold" ~ ecozone_koppen_15,
      ecozone_koppen_5 == "Temperate" ~ ecozone_koppen_15,
      .default = ecozone_koppen_5
    )
  ) %>%
  dplyr::filter(
    region != "Africa"
  ) %>%
  dplyr::mutate(sel_classification = as.factor(sel_classification)) %>%
  dplyr::inner_join(
    data_climate_zones, # [config criteria]
    .,
    by = "sel_classification"
  ) %>%
  dplyr::mutate(
    region = factor(region,
      levels = vec_regions # [config criteria]
    )
  )
```

```{r}
#| label: plot data pollen spatial distribution
fig_map <-
  data_pollen %>%
  dplyr::inner_join(
    data_meta,
    by = "dataset_id"
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = long,
      y = lat
    )
  ) +
  ggplot2::scale_fill_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::scale_color_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::theme_classic() +
  ggplot2::theme(
    text = ggplot2::element_text(
      size = text_size # [config criteria]
    ),
    line = ggplot2::element_line(
      linewidth = line_size # [config criteria]
    ),
    legend.position = "none",
    plot.margin = grid::unit(c(0.1, 0.1, 0.1, 0.1), "mm")
  ) +
  ggplot2::coord_equal(
    ratio = 1.3,
    ylim = range(data_meta$lat),
    xlim = range(data_meta$long)
  ) +
  ggplot2::labs(
    title = "A) Spatial coverage and distribution of records",
    x = expression(
      paste(
        "Longitude ", (degree ~ E)
      )
    ),
    y = expression(
      paste(
        "Latitude ", (degree ~ N)
      )
    )
  ) +
  ggplot2::scale_x_continuous(
    breaks = seq(-180, 180, by = 50)
  ) +
  ggplot2::scale_y_continuous(
    breaks = seq(-90, 90, by = 15)
  ) +
  ggplot2::geom_polygon(
    data = ggplot2::map_data("world") %>%
      dplyr::filter(lat > -60 & lat < 85),
    ggplot2::aes(
      group = group
    ),
    fill = "grey80",
    alpha = 0.4
  ) +
  ggplot2::geom_point(
    mapping = ggplot2::aes(
      col = sel_classification
    ),
    size = 3,
    shape = 19,
    alpha = 0.1
  ) +
  ggplot2::geom_point(
    mapping = ggplot2::aes(
      col = sel_classification
    ),
    size = 0.5,
    shape = 20,
    alpha = 1
  ) +
  ggplot2::geom_point(
    col = "grey30",
    size = 0.1,
    shape = 20,
    alpha = 1
  )

fig_recod_count <-
  data_pollen %>%
  dplyr::inner_join(
    data_meta,
    by = "dataset_id"
  ) %>%
  dplyr::group_by(region, sel_classification) %>%
  dplyr::count(
    name = "n_records"
  ) %>%
  dplyr::mutate(
    region = factor(
      region,
      levels = c(
        "North America",
        "Europe",
        "Asia",
        "Latin America",
        "Oceania"
      )
    )
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      y = n_records,
      x = sel_classification,
      col = sel_classification,
      fill = sel_classification
    )
  ) +
  ggplot2::facet_wrap(
    ~region,
    nrow = 2,
    dir = "h"
  ) +
  ggplot2::scale_fill_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::scale_color_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::theme_bw() +
  ggplot2::theme(
    text = ggplot2::element_text(
      size = text_size # [config criteria]
    ),
    line = ggplot2::element_line(
      linewidth = line_size # [config criteria]
    ),
    plot.caption.position = "panel",
    strip.background = ggplot2::element_blank(),
    strip.text = ggplot2::element_text(
      size = text_size,
      hjust = 0.01
    ),
    axis.text.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank(),
    axis.title = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.grid.major.x = ggplot2::element_blank(),
    legend.position = "none",
    plot.margin = grid::unit(c(0.1, 0.1, 0.1, 0.1), "mm")
  ) +
  ggplot2::labs(
    y = "Number of records",
    title = "B) Number of records in each climate zone"
  ) +
  ggplot2::geom_segment(
    mapping = ggplot2::aes(
      xend = sel_classification,
      yend = 0
    ),
    col = "grey30"
  ) +
  ggplot2::geom_point(
    size = 3,
    shape = 21,
    col = "grey30"
  ) +
  ggplot2::geom_text(
    mapping = ggplot2::aes(
      label = n_records
    ),
    nudge_y = 20,
    col = "grey30",
    size = text_size / 3
  )

fig_color_legend <-
  data_meta %>%
  dplyr::distinct(sel_classification) %>%
  dplyr::mutate(
    climate_zone_name = dplyr::case_when(
      .default = sel_classification,
      sel_classification == "Cold_Without_dry_season_Very_Cold_Summer" ~ "Cold - without dry season - very cold summer",
      sel_classification == "Cold_Without_dry_season_Cold_Summer" ~ "Cold - without dry season - cold summer",
      sel_classification == "Cold_Without_dry_season_Warm_Summer" ~ "Cold - without dry season - warm summer",
      sel_classification == "Cold_Without_dry_season_Hot_Summer" ~ "Cold - without dry season - hot summer",
      sel_classification == "Cold_Dry_Winter" ~ "Cold - dry winter",
      sel_classification == "Cold_Dry_Summer" ~ "Cold - dry summer",
      sel_classification == "Temperate_Without_dry_season" ~ "Temperate - without dry season",
      sel_classification == "Temperate_Dry_Winter" ~ "Temperate - dry winter",
      sel_classification == "Temperate_Dry_Summer" ~ "Temperate - dry summer"
    ),
    climate_zone_name = factor(
      climate_zone_name,
      levels = c(
        "Arid",
        "Tropical",
        "Temperate - dry summer",
        "Temperate - dry winter",
        "Temperate - without dry season",
        "Cold - dry summer",
        "Cold - dry winter",
        "Cold - without dry season - hot summer",
        "Cold - without dry season - warm summer",
        "Cold - without dry season - cold summer",
        "Cold - without dry season - very cold summer",
        "Polar"
      )
    )
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = 1,
      y = climate_zone_name,
      label = climate_zone_name,
      col = sel_classification,
      fill = sel_classification
    )
  ) +
  ggplot2::coord_cartesian(
    xlim = c(0, 20)
  ) +
  ggplot2::scale_fill_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::scale_color_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::theme_void() +
  ggplot2::theme(
    text = ggplot2::element_text(
      size = text_size # [config criteria]
    ),
    line = ggplot2::element_line(
      linewidth = line_size # [config criteria]
    ),
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    plot.caption.position = "panel",
    legend.position = "none",
    plot.margin = grid::unit(c(0.1, 0.1, 0.1, 0.1), "mm")
  ) +
  ggplot2::labs(
    title = "C) Climate zone color legend"
  ) +
  ggplot2::geom_point(
    shape = 22,
    col = "gray30",
    size = 10
  ) +
  ggplot2::geom_text(
    mapping = ggplot2::aes(
      x = 2
    ),
    col = "grey30",
    size = text_size / 3,
    hjust = 0
  )

cowplot::plot_grid(
  fig_map,
  fig_color_legend,
  nrow = 1,
  rel_widths = c(1, 0.2)
)

plot(fig_recod_count)


```

```{r}
#| label: plot data pollen temporal distribution
fig_temporal <-
  data_pollen %>%
  tidyr::unnest(levels) %>%
  dplyr::inner_join(
    data_meta,
    by = "dataset_id"
  ) %>%
  dplyr::group_by(
    region, sel_classification, dataset_id
  ) %>%
  dplyr::summarise(
    .groups = "drop",
    age_min = min(age),
    age_max = max(age),
    age_mean = mean(age)
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age_min,
      xend = age_max,
      y = reorder(dataset_id, age_mean),
      yend = reorder(dataset_id, age_mean),
      col = sel_classification
    )
  ) +
  ggplot2::facet_wrap(
    scales = "free_y",
    ~region,
    ncol = 1
  ) +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::scale_fill_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::scale_color_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::theme_bw() +
  ggplot2::theme(
    text = ggplot2::element_text(
      size = text_size # [config criteria]
    ),
    line = ggplot2::element_line(
      linewidth = line_size # [config criteria]
    ),
    plot.caption.position = "panel",
    strip.background = ggplot2::element_blank(),
    strip.text = ggplot2::element_text(
      size = text_size,
      hjust = 0.01
    ),
    axis.text.y = ggplot2::element_blank(),
    axis.ticks.y = ggplot2::element_blank(),
    axis.title.y = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.grid.major.y = ggplot2::element_blank(),
    legend.position = "none",
    plot.margin = grid::unit(c(0.1, 0.1, 0.1, 0.1), "mm")
  ) +
  ggplot2::labs(
    title = "D) Temporal coverage of records",
    x = "Age (cal yr BP)"
  ) +
  ggplot2::geom_segment(
    alpha = 0.5,
    linewidth = 0.5
  )

plot(fig_temporal)
```
```{r}
#| label: plot data pollen taxa
data_pollen_taxa <-
  data_pollen %>%
  dplyr::mutate(
    taxa = purrr::map(
      .progress = TRUE,
      .x = counts_harmonised,
      .f = ~ .x %>%
        dplyr::select(-sample_id) %>%
        names()
    )
  ) %>%
  dplyr::select(
    dataset_id, taxa
  )

data_pollen_taxa_n_per_dataset <-
  data_pollen_taxa %>%
  dplyr::mutate(
    n_taxa = purrr::map_dbl(
      .progress = TRUE,
      .x = taxa,
      .f = ~ length(.x)
    )
  ) %>%
  dplyr::inner_join(
    data_meta,
    by = "dataset_id"
  ) %>%
  dplyr::mutate(
    region = factor(
      region,
      levels = c(
        "North America",
        "Europe",
        "Asia",
        "Latin America",
        "Oceania"
      )
    )
  )

data_pollen_taxa_per_continnt <-
  data_pollen_taxa %>%
  tidyr::unnest(taxa) %>%
  dplyr::inner_join(
    data_meta,
    by = "dataset_id"
  ) %>%
  dplyr::distinct(region, sel_classification, taxa) %>%
  dplyr::group_by(region, sel_classification) %>%
  dplyr::count(
    name = "n_taxa"
  ) %>%
  dplyr::mutate(
    region = factor(
      region,
      levels = c(
        "North America",
        "Europe",
        "Asia",
        "Latin America",
        "Oceania"
      )
    )
  )


fig_taxa_basic <-
  tibble::tibble() %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      y = n_taxa,
      x = sel_classification,
      col = sel_classification,
      fill = sel_classification
    )
  ) +
  ggplot2::facet_wrap(
    ~region,
    nrow = 2,
    dir = "h"
  ) +
  ggplot2::scale_fill_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::scale_color_manual(
    values = palette_ecozones # [config criteria]
  ) +
  ggplot2::theme_bw() +
  ggplot2::theme(
    text = ggplot2::element_text(
      size = text_size # [config criteria]
    ),
    line = ggplot2::element_line(
      linewidth = line_size # [config criteria]
    ),
    plot.caption.position = "panel",
    strip.background = ggplot2::element_blank(),
    strip.text = ggplot2::element_text(
      size = text_size,
      hjust = 0.01
    ),
    axis.text.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank(),
    axis.title = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.grid.major.x = ggplot2::element_blank(),
    legend.position = "none",
    plot.margin = grid::unit(c(0.1, 0.1, 0.1, 0.1), "mm")
  )

fig_taxa_continent <-
  fig_taxa_basic +
  ggplot2::labs(
    y = "Number of taxa",
    title = "E) Total number of taxa in each climate zone"
  ) +
  ggplot2::geom_segment(
    data = data_pollen_taxa_per_continnt,
    mapping = ggplot2::aes(
      xend = sel_classification,
      yend = 0
    ),
    col = "grey30"
  ) +
  ggplot2::geom_point(
    data = data_pollen_taxa_per_continnt,
    size = 3,
    shape = 21,
    col = "grey30"
  ) +
  ggplot2::geom_text(
    data = data_pollen_taxa_per_continnt,
    mapping = ggplot2::aes(
      label = n_taxa
    ),
    nudge_y = 70,
    col = "grey30",
    size = text_size / 3
  )

fig_taxa_per_record <-
  fig_taxa_basic +
  ggplot2::labs(
    y = "Number of taxa",
    title = "F) The number of taxa per record in each climate zone"
  ) +
  ggplot2::geom_jitter(
    data = data_pollen_taxa_n_per_dataset,
    alpha = 0.3
  ) +
  ggplot2::geom_violin(
    data = data_pollen_taxa_n_per_dataset,
    alpha = 0.3,
    col = NA
  ) +
  ggplot2::geom_boxplot(
    data = data_pollen_taxa_n_per_dataset,
    fill = "white",
    col = "grey30",
    width = 0.1,
    outlier.shape = NA
  ) +
  ggplot2::geom_point(
    data = data_pollen_taxa_n_per_dataset %>%
      dplyr::group_by(region, sel_classification) %>%
      dplyr::summarise(
        median = median(n_taxa)
      ),
    mapping = ggplot2::aes(
      y = median
    ),
    shape = 22,
    col = "gray30",
    size = 3
  )

cowplot::plot_grid(
  fig_taxa_continent,
  fig_taxa_per_record,
  nrow = 1
)
``` 

## Example record

Let's select a one record and use it as an example.

```{r}
#| label: plot example record
sel_example_record <- "4197"

sel_data <-
  data_meta  %>% 
  dplyr::filter(
    dataset_id == sel_example_record
  )

sitename <- 
  sel_data$handle

x_lim <-
  range(sel_data$long)

y_lim <-
  range(sel_data$lat)

border_val <- 10

p_position <-
  sel_data %>%
  ggplot2::ggplot(
    ggplot2::aes(
      x = long,
      y= lat,
      col = sel_classification)
  ) +
  ggplot2::borders(
    fill = "gray90", colour = "gray75"
  ) +
  ggplot2::geom_point(
    size = 3,
    colour = "black"
  ) +
  ggplot2::geom_point(
    size = 1,
    colour = "white"
  ) +
  ggplot2::coord_quickmap(
    xlim = c(min(x_lim) - border_val, max(x_lim) + border_val),
    ylim = c(min(y_lim) - border_val, max(y_lim) + border_val)
  ) +
  ggplot2::labs(
    x = "longitude",
    y = "latitude"
  ) +
  ggplot2::scale_color_manual(
      values = palette_ecozones,
  ) +
  ggplot2::theme(
    legend.position = "none"
  )

p_position +
  ggplot2::geom_text(
    ggplot2::aes(
      label = sitename
    ),
    vjust = 0.1,
    nudge_y = 1,
    size = 7
  ) +
  ggplot2::geom_point(
    size = 10
  ) +
  ggplot2::geom_point(
    size = 3,
    colour = "white"
  ) +
  ggplot2::labs(
    subtitle = stringr::str_wrap("Location of the selected record", fig_width_def)
  )
```

# Detection of past human presence

To determine the impact of past humans on fundamental ecosystem properties, we need to develop indicators of past human presence and activity. This led to the development of a new method, where we use human event detection and indicators identified from pollen records based on expert knowledge, combined with the method for quantifying human presence based on radiocarbon dates derived from archaeological artifacts and Summed Probability Densities (SPD) (Bird et al. 2022). We believe that this solves the issue that we can use a standardised variable as indicator of past human impact, and partially avoids the difficulty of creating standardised variables to detect human disturbance events across different regions and continents. This may reduce the potential circularity of human detection events derived from the same pollen records as the estimates of ecosystem properties.  

## Detection of human events

For each pollen record, we have detected periods of human presence from the pollen data. Two methods have been used: 

1.  detection from pollen diagrams (North America, Europe, Asia, Indopacific)
2.  detection using indicator taxa (Latin America).  

### Detection of human events in pollen diagrams 

First, a pollen diagram of each pollen record has been examined by a regional expert and the age of each event type has been recorded.

```{r}
#| label: table event types
#| tbl-cap: Table 2 Type of human events identified in pollen diagrams
event_table <-
  data.frame(
    Region = c(
      "North America",
      "Europe",
      "Asia",
      "Indopasific"
    ),
    `Event-type` = c(
      paste(
        "BI = Before Impact; FC = First Cultivation; ES = European Settlement"
      ),
      paste(
        "BI = Before Impact; FI = First Indication; FCu = First Cultivation; EC = Extensive Clearance; CC = Complete Clearance"
      ),
      paste(
        "BI = Before Impact; FI = First Indication; FCu = First Cultivation; EI = Extensive Impact"
      ),
      paste(
        "no_impact = No Impact; weak = Weak Impact; medium = Medium Impact; strong = Strong Impact"
      )
    )
  )

event_table %>%
  pander::pandoc.table(
    caption = "Table 2: Type of human events identified in pollen diagrams"
  )
```

Note that the event types are uniquely defined within continents, and event types with the same name have different meanings between continents.    

Second, an algorithm is made to obtain the binary variables (0/1) associated with each event type that is identified in each pollen record. A new vector with the average ages in between levels (samples) of the identified event type was created because the time of the events is assumed to have occurred prior to the changed event. A new matrix was created that uses the new age vector with the events type. The different event types are assigned binary values (0/ 1) depending on if the event type is present (i.e. when the age of the specific event is detected). Ultimately, logical principles were followed and the binary values were adjusted to get the event data for each pollen record. If no human event is recognised, it does not necessarily mean that humans were absent, but instead that there was not enough information to identify human activity in the pollen records.  

Below is a figure that intends to represent the data associated with human events in example record. The different colours represent the differnet types of human events in each region. The smooth trend lines represent simple binomial GAM models  that show the main trends and alteration in the timing of events over time.

```{r}
#| label: plot events
data_events <-
  targets::tar_read(
    name = "data_events_to_fit",
    store = external_storage_targets
  )

data_events_sel <-
  data_events  %>% 
  tidyr::unnest(data_to_fit)  %>% 
  dplyr::filter(
    dataset_id %in% sel_example_record
  )  %>% 
  tidyr::nest(
    data_to_fit = -var_name
  )

suppressWarnings(
  plot_data_events(
    data_source_events = data_events_sel,
    sel_k = 50
  ) +
    ggplot2::labs(
      title = stringr::str_wrap("Temporal trend for selected record", fig_width_def),
    )
)
```

## Arcehological artefacts and Summed Probability Densities

The quantification of *summed probability distribution* (SPD). requires a distance to be selected around each site location to collect the relevant dates of archaeological artefacts around it. This will limit the area of human presence and indirectly the amount of human activity relevant to pollen records from each site.  

```{r}
#| label: rc settings
dist_vect <-
  c(5, 25, 50, 100, 250, 500) %>%
  rlang::set_names()

min_n_rc_dates <- 250
```

We used the global dataset of radicarbon dates (RC dates) of archeological artefacts from Bird et al. 2022.

We have gathered all radiocarbon dates up to `r max(dist_vect)` km away and split them into groups (categories) by the distance to the sequence.

Only RC dates with valid geographical location (longitude and latitude), and 'LocAccuracy' > 0 were selected. For each pollen record, RC dates were classified by the geographical distance to the pollen record. The chosen distance classes were: 5, 25, 50, 100, 250, 500 km. For each distance category, we used all RC dates up to the maximum distance of selected category. For example, `250` contains all RC dates up to 250 km including `5`, `25`,...

However, distance class with less than (`r min_n_rc_dates` RC dates) (a *Threshold*) is filtered out in order to maintain robust SPD estimation. 

```{r}
#| label: plot C14 for exmple record
data_c14_subset <-
  targets::tar_read(
    name = "data_c14_subset",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

# this is litle trick to split data into bins unig `findInterval` function
sel_dist_vect <-
    c(0, 5, 25, 50, 100, 250, 500) %>%
    rlang::set_names(
        nm = c(5, 25, 50, 100, 250, 500, Inf)
    )

sel_rc <-
    data_c14_subset %>%
    dplyr::filter(dataset_id == sel_example_record) %>%
    tidyr::unnest(rc) %>%
    dplyr::mutate(
        dist_bin = names(sel_dist_vect)[findInterval(
            dist,
            sel_dist_vect,
            all.inside = TRUE
        )] %>%
            as.character()
    )

sel_dist_to_plot <-
    sel_dist_vect[1:(length(sel_dist_vect) - 1)]

basic_col <-
  palette_ecozones[
    names(palette_ecozones) == data_meta %>%
      dplyr::filter(
        dataset_id == sel_example_record
      ) %>%
      purrr::pluck("sel_classification", 1)
  ]

pallette_dist_vec <-
  colorRampPalette(
    c(
      colorspace::darken(basic_col, amount = 0.5),
      basic_col,
      colorspace::lighten(basic_col, amount = 0.75)
    )
  )(length(sel_dist_to_plot)) %>%
  purrr::set_names((names(sel_dist_to_plot)))

p_rc_1 <-
    p_position +
    ggplot2::geom_point(
        data = sel_rc,
        ggplot2::aes(
            long, lat,
            col = dist_bin
        ),
        size = 2,
        alpha = 0.75
    ) +
    ggplot2::scale_color_manual(
        values = pallette_dist_vec
    ) +
    ggplot2::labs(
        colour = "distance to the site (km)",
        subtitle = stringr::str_wrap("Location of selected RC dates by their distance", fig_width_def * 0.75)
    )

data_rc_count <-
    names(sel_dist_to_plot) %>%
    rlang::set_names() %>%
    purrr::map_dfr(
        .id = "max_dist",
        .f = ~ sel_rc %>%
            dplyr::filter(dist < as.numeric(.x))
    ) %>%
    dplyr::group_by(max_dist, dist_bin) %>%
    dplyr::count() %>%
    dplyr::arrange(as.numeric(max_dist), as.numeric(dist_bin)) %>%
    dplyr::mutate(
        max_dist = factor(max_dist, levels = names(sel_dist_to_plot)),
        dist_bin = factor(dist_bin, levels = names(sel_dist_to_plot))
    )

valid_dist <-
    data_rc_count %>%
    dplyr::group_by(max_dist) %>%
    dplyr::summarise(
        n = sum(n)
    ) %>%
    dplyr::filter(n > min_n_rc_dates) %>% # [config]
    purrr::pluck("max_dist")

p_rc_2 <-
    data_rc_count  %>% 
    ggplot2::ggplot() +
    ggplot2::geom_bar(
        ggplot2::aes(
            max_dist,
            n,
            fill = dist_bin
        ),
        stat = "identity",
        col = "gray75",
        size = line_size
    ) +
    ggplot2::geom_hline(
        yintercept = min_n_rc_dates, # [config]
        colour = "gray30",
        linewidth = 1,
        lty = 2
    ) +
    geom_curve(
         data = data.frame(
            x1 = 2,
            x2 = 1,
            y1 = 1e3,
            y2 = 300
        ),
        aes(x = x1, y = y1, xend = x2, yend = y2),
        curvature = 0.25,
        arrow = arrow(length = unit(0.03, "npc"))
    ) +
    geom_text(
        data = data.frame(
            x = 2,
            y = 1e3,
            text = "Threshold"
        ),
        aes(x, y, label = text),
        size = 7,
        hjust = 0.5,
        vjust = 0.5,
        nudge_y = 200
    ) +
    ggplot2::scale_fill_manual(
        values = pallette_dist_vec
    ) +
    ggplot2::theme(
        legend.position = "bottom",
        axis.ticks.x = ggplot2::element_blank()
    ) +
    ggplot2::labs(
        x = "Maximum distance to the site (km)",
        y = "Number of RC dates",
        fill = "distance to the site (km)",
        subtitle = stringr::str_wrap("Number of RC dates in each distance category", fig_width_def * 0.75)
    )

common_legend <-
    ggpubr::get_legend(p_rc_2)

ggpubr::ggarrange(
    ggpubr::ggarrange(
        p_rc_1 +
            ggplot2::theme(legend.position = "none"),
        p_rc_2 +
            ggplot2::theme(legend.position = "none")
    ),
    common_legend,
    nrow = 2,
    heights = c(10, 1)
)
```

### Estimation of SPD

For each distance category, SPD is estimated using `spd` function from `rcarbon` package for each distance class for each year between a minimum threshold age and 12 ka. 

Radiocarbon dates were calibrated using `calibrate` function from `rcarbon` package with appropriate calibration curves ("IntCal20", "ShCal20", "mixed"). Calibration curves were obtained `rcarbon` package and "mixed" was created using `rcarbon::mixCurves` function with 'p' = 0.5. Calibration curves were assigned by their geographical location following Hua et al., 2013.  

```{r}
#| label: detect spd curve
sel_cal_curve <-
  data_c14_subset  %>% 
    dplyr::filter(
      dataset_id == sel_example_record
  )  %>% 
  purrr::pluck("curve_name")

```

For the selected seqeunces **`r sel_cal_curve`** have been used.

The temporal distribution of SPDs constructed by diferent distances:

```{r}
#| label: plot temporal spd trend
data_spd <-
    targets::tar_read(
      name = "data_spd",
       store = paste0(
         data_storage_path,
         "_targets_h1"
       )
    )

data_spd_sel_raw <-
    data_spd %>%
    dplyr::filter(
        dataset_id == sel_example_record
    )  %>% 
    tidyr::unnest(spd)  %>% 
    dplyr::select(-dataset_id)

data_spd_sel <-
    data_spd_sel_raw %>%
    tidyr::pivot_longer(
        cols = -age
    ) %>%
    dplyr::mutate(
        name = stringr::str_replace(name, "x", ""),
        name = factor(name, levels = dist_vect) # [config]
    ) %>%
    # limit to only plot the dates present
    dplyr::filter(
        name %in% valid_dist
    )

p2 <-
  plot_template_temporal +
  ggplot2::facet_wrap(~name, ncol = 1) +
  ggplot2::scale_fill_manual(
    values = pallette_dist_vec
  ) +
  ggplot2::theme(
    axis.title.y = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank(),
    axis.line.y = ggplot2::element_blank(),
    axis.ticks.y = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    subtitle = stringr::str_wrap("Temporal distribution of SPD", fig_width_def * 2)
  ) +
  ggplot2::guides(
    colour = "none",
    fill = "none"
  ) +
  ggplot2::geom_ribbon(
    data = data_spd_sel,
    ggplot2::aes(
      y = value,
      ymin = 0,
      ymax = value,
      fill = name
    )
  )

pallette_dist_vec_sub <-
    pallette_dist_vec[names(pallette_dist_vec) %in% unique(data_spd_sel$name)]

color_facets(
    sel_plot = p2,
    sel_palette = pallette_dist_vec_sub
)
```

### Regional age cutoff

The minimum threshold ages are different for different regions and are decided based on the availability of radiocarbon dating for different regions. In general there is a bias that radiocarbon dating is rather limited on younger material where in many regions there are a lack of C14 data during the last 2000 years. Table 5 show the ages where data younger than age_from where removed.  

```{r}
#| label: regional age cutoff
age_cutoff_rc <-
  data.frame(
    region = c(
      "Europe",
      "Latin America",
      "Asia",
      "North America",
      "Oceania"
    ),
    age_from = c(2000, 2000, 2000, 500, 500)
  )

age_cutoff_rc %>%
  pander::pandoc.table(
    capttion = "Table 5: Minimum ages above which C14 data was removed (age_from) for different regions"
  )
```

### Selection of the distance
In order to select the *best distance*, we want to know, which SPD curve is the best at explaining the changes in pollen events.

Therefore, for each distance, we calculated *Redundancy Analysis* (RDA) with individual event values as response and SPD as predictors.

Here is a visualisation of the data to fit:
```{r}
#| label: plot joined sdp & events
event_types_vec <-
  c(
    "no impact",
    "first impact",
    "emerging impact",
    "extensive clearince",
    "complete clearince",
    "first cultivation",
    "europiean settlement",
    "weak impact",
    "medium impact",
    "strong impact"
  )

data_events_to_plot <-
  data_events_sel %>%
  tidyr::unnest(data_to_fit) %>%
  dplyr::select(-dataset_id) %>%
  dplyr::mutate(
    var_name = dplyr::case_when(
      .default = "no impact",
      var_name == "bi" ~ "no impact",
      var_name == "fi" ~ "first impact",
      var_name == "ei" ~ "emerging impact",
      var_name == "ec" ~ "extensive clearince",
      var_name == "cc" ~ "complete clearince",
      var_name == "fc" ~ "first cultivation",
      var_name == "es" ~ "europiean settlement",
      var_name == "weak" ~ "weak impact",
      var_name == "medium" ~ "medium impact",
      var_name == "strong" ~ "strong impact"
    ),
    var_name = factor(
      var_name,
      levels = event_types_vec
    )
  )

palette_events <-
  c(
    "grey60",
    "#c99000",
    "#a17400",
    "#7b5800",
    "#573e00",
    "#00c92b",
    "#c9009e",
    "#9b541b",
    "#5d261a",
    "#1f0000"
  ) %>%
  rlang::set_names(
    levels(data_events_to_plot$var_name)
  )

p1_vertical <-
  plot_template_temporal +
  ggplot2::geom_tile(
    data = data_events_to_plot,
    ggplot2::aes(
      y = 1,
      fill = var_name,
      alpha = value
    ),
    col = "gray95",
  ) +
  ggplot2::facet_wrap(. ~ var_name, nrow = 1, scales = "free_x") +
  ggplot2::scale_fill_manual(
    values = palette_events
  ) +
  ggplot2::scale_color_manual(
    values = palette_events
  ) +
  ggplot2::scale_alpha_continuous(
    range = c(0, 1)
  ) +
  ggplot2::coord_flip(
    xlim = c(8.5e3, 0)
  ) +
  ggplot2::theme(
    axis.title.x = ggplot2::element_blank(),
    axis.text.x = ggplot2::element_blank(),
    axis.line.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank()
  ) +
  ggplot2::guides(
    colour = "none",
    fill = "none",
    alpha = "none"
  )

p3_vertical <-
  plot_template_temporal +
  ggplot2::geom_tile(
    data = data_spd_sel,
    ggplot2::aes(
      y = name,
      fill = name,
      alpha = value
    ),
    col = NA
  ) +
  ggplot2::facet_wrap(. ~ name, nrow = 1, scales = "free_x") +
  ggplot2::scale_fill_manual(
    values = pallette_dist_vec
  ) +
  ggplot2::scale_alpha_continuous(
    range = c(0, 1)
  ) +
  ggplot2::coord_flip(
    xlim = c(8.5e3, 0)
  ) +
  ggplot2::theme(
    axis.title = ggplot2::element_blank(),
    axis.text = ggplot2::element_blank(),
    axis.line.x = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank()
  ) +
  ggplot2::guides(
    colour = "none",
    fill = "none",
    alpha = "none"
  )

ggpubr::ggarrange(
  color_facets(
    sel_plot = p1_vertical,
    sel_palette = palette_events,
    direction = "horizontal",
    return_raw = TRUE
  ) %>%
    ggplotify::as.ggplot(),
  color_facets(
    sel_plot = p3_vertical,
    sel_palette = pallette_dist_vec_sub,
    direction = "horizontal",
    return_raw = TRUE
  ) %>%
    ggplotify::as.ggplot(),
  align = "h"
)
```

Or in a form of table:

```{r}
#| label: RDA data to fit
data_to_fit_rda <-
    dplyr::inner_join(
        data_spd_sel %>%
            tidyr::pivot_wider(
                names_from = "name",
                values_from = "value",
                values_fill = 0
            ),
        data_events_to_plot %>%
            tidyr::pivot_wider(
                names_from = "var_name",
                values_from = "value",
                values_fill = 0
            ),
        by = "age"
    ) %>%
    dplyr::arrange(age) %>%
    tibble::column_to_rownames("age")  %>% 
    dplyr::relocate(
        dplyr::any_of(event_types_vec)
    ) 

data_to_fit_rda_events <-
    data_to_fit_rda %>%
    dplyr::select(
        dplyr::any_of(
            event_types_vec
        )
    )

data_to_fit_rda %>%
  round(., 5) %>%
  tibble::rownames_to_column("age") %>%
  head() %>%
  pander::pandoc.table()
```

We can plot the individual ordianation but it is not very informative.
The size and ocupancy of points corespond with their age.

```{r}
#| label: RDA ordination
data_rda <-
    tibble::tibble(
        valid_dist
    ) %>%
    dplyr::mutate(
        valid_dist_num = as.numeric(as.character(valid_dist)),
        ord = purrr::map(
            .x = valid_dist_num,
            .f = ~ vegan::rda(
                as.formula(
                    paste0(
                        "data_to_fit_rda_events ~ `", eval(.x), "`"
                    )
                ),
                data = data_to_fit_rda
            ) %>%
                return()
        )
    ) %>%
    dplyr::mutate(
        adj_Rsquared = purrr::map_dbl(
            .x = ord,
            .f = ~ {
                res <-
                    vegan::RsquareAdj(.x) %>%
                    purrr::pluck("adj.r.squared")

                if (
                    is.null(res)
                ) {
                    return(0)
                } else {
                    return(res)
                }
            }
        )
    )

ggpubr::ggarrange(
    plotlist = purrr::map(
        .x = data_rda$ord,
        .f = ~ tibble::tibble() %>%
          ggplot2::ggplot(
            ggplot2::aes(
              RDA1, PC1
            )
          ) +
          ggplot2::geom_vline(
            xintercept = 0
          ) +
          ggplot2::geom_hline(
            yintercept = 0
          ) +
          ggplot2::geom_point(
            data = vegan::scores(.x, display = "sites") %>%
              as.data.frame() %>%
              tibble::rownames_to_column("age") %>%
              dplyr::mutate(age = as.numeric(age)),
            aes(size = age, alpha = age),
          ) +
          ggplot2::scale_size_continuous(
            range = c(3, 7)
          ) +
          geom_segment(
            data = vegan::scores(.x, display = "species") %>%
              as.data.frame() %>%
              tibble::rownames_to_column("event_type"),
            aes(x = 0, y = 0, xend = RDA1, yend = PC1, col = event_type),
            arrow = arrow(length = unit(0.03, "npc")),
            size = 1
          ) +
          ggplot2::guides(
            size = "none",
            alpha = "none"
          ) +
          ggplot2::coord_fixed() +
          ggplot2::theme_void() +
          ggplot2::scale_color_manual(
            values = palette_events
          )
    ),
    common.legend = TRUE,
    legend = "bottom",
    labels = c(valid_dist),
    nrow = 2,
    ncol = 2
)

```

#### R2

We can evaluate the amount of variability explained by each ordination.
We then extracted adj.r2 for each SPD distnce:

```{r}
#| label: RDA R2
data_r2 <-
    data_rda %>%
    dplyr::select(
        distance = valid_dist,
        adj_Rsquared
    )

best_dis <-
    data_r2 %>%
    dplyr::filter(
        adj_Rsquared == max(adj_Rsquared)
    ) %>%
    purrr::pluck("distance")

dist_order <-
    which(data_r2$distance == best_dis)

max_r2 <- 
    max(data_r2$adj_Rsquared)

max_r2_to_plot <-  
    ifelse(max_r2 > 0.35, 0.75, 0.5)

data_r2  %>% 
    ggplot2::ggplot(
         aes(x = distance, y = adj_Rsquared)
    ) +
    ggplot2::geom_segment(
        aes(
            xend = distance,
            y = 0,
            yend = adj_Rsquared
        )
    ) +
    ggplot2::geom_point(
        size = 10,
        colour = "gray30"
    ) +
    ggplot2::geom_point(
        ggplot2::aes(col = distance),
        size = 9
    ) +
    ggplot2::geom_segment(
         data = data.frame(
            x1 = dist_order,
            x2 = dist_order,
            y1 = (max_r2_to_plot * 0.9),
            y2 = (max_r2 * 1.1)
        ),
        ggplot2::aes(x = x1, y = y1, xend = x2, yend = y2),
        arrow = arrow(length = unit(0.03, "npc"))
    ) +
    ggplot2::geom_text(
        data = data.frame(
            x = dist_order,
            y = (max_r2_to_plot * 0.9),
            text = "Best"
        ),
        ggplot2::aes(x, y, label = text),
        size = 7,
        hjust = 0.5,
        vjust = 0.1,
        nudge_y = max_r2_to_plot * 0.01
    ) +
    ggplot2::scale_color_manual(
        values = pallette_dist_vec_sub
    ) +
    ggplot2::guides(
        colour = "none"
    ) +
    ggplot2::labs(
        x = "Distance (km)",
        y = "Adjusted R-square"
    ) +
    ggplot2::scale_y_continuous(
        limits = c(0, max_r2_to_plot)
    )
```

Therefore we have selected **`r best_dis`** as the best distance and the prefered SPD curve for **`r sel_example_record`** sequence

## Selecting best distance per continent

Here is a overview of the status of records base on the presence of humna impact from pollen diagrams and RC data 

```{r}
#| label: status of records based on events and rc
data_valid_n_rc_raw <-
  dplyr::left_join(
    data_meta,
    data_c14_subset,
    by = "dataset_id"
  ) %>%
  dplyr::mutate(
    has_rc = purrr::map_lgl(
      .x = rc,
      .f = ~ is.data.frame(.x)
    )
  ) %>%
  dplyr::mutate(
    n_rc = purrr::map2_dbl(
      .x = has_rc,
      .y = rc,
      .f = ~ ifelse(.x, nrow(.y), 0)
    )
  ) %>%
  dplyr::mutate(
    has_valid_n_rc = purrr::map_lgl(
      .x = n_rc,
      .f = ~ .x >= 50
    )
  ) %>%
  dplyr::distinct(
    region, sel_classification, dataset_id, has_valid_n_rc
  ) %>%
  tidyr::drop_na(region, sel_classification)

data_id_has_human_impact <-
  data_events %>%
  dplyr::filter(
    !var_name %in% c("bi", "no_impact")
  ) %>%
  tidyr::unnest(data_to_fit) %>%
  dplyr::filter(value == 1) %>%
  dplyr::distinct(dataset_id) %>%
  dplyr::mutate(
    have_events = TRUE
  )

data_valid_events_raw <-
  data_meta %>%
  dplyr::left_join(
    data_id_has_human_impact,
    by = "dataset_id"
  ) %>%
  dplyr::mutate(
    have_events = ifelse(is.na(have_events), FALSE, have_events)
  )

 dplyr::full_join(
   data_valid_n_rc_raw,
   data_valid_events_raw,
   by = dplyr::join_by(region, sel_classification, dataset_id)
 ) %>%
   dplyr::mutate(
     status = dplyr::case_when(
       have_events == TRUE & has_valid_n_rc == TRUE ~
         "human presence & enough RC",
       have_events == TRUE & has_valid_n_rc == FALSE ~
         "human presence but not enough RC",
       have_events == FALSE & has_valid_n_rc == TRUE ~
         "no human presence but enough RC",
       .default = "no human presence & not enough RC"
     )
   ) %>%
   dplyr::mutate(
     status = factor(
       status,
       levels = c(
         "human presence & enough RC",
         "human presence but not enough RC",
         "no human presence but enough RC",
         "no human presence & not enough RC"
       )
     )
   ) %>%
   dplyr::group_by(region, sel_classification, status) %>%
   dplyr::count(
     name = "N"
   ) %>%
   dplyr::ungroup() %>%
   dplyr::mutate(N = as.double(N)) %>%
   dplyr::arrange(
     region, sel_classification, status
   ) %>%
   tidyr::complete(
     region,
     sel_classification,
     status,
     fill = list(N = 0.00001)
   ) %>%
   ggplot2::ggplot() +
   ggplot2::facet_grid(
     region ~ sel_classification
   ) +
   ggplot2::theme_bw() +
   ggplot2::guides(
     fill = ggplot2::guide_legend(ncol = 1)
   ) +
   ggplot2::theme(
     axis.title = ggplot2::element_blank(),
     axis.ticks = ggplot2::element_blank(),
     axis.text = ggplot2::element_blank(),
     legend.position = "right",
     plot.caption.position = "panel",
     strip.background = ggplot2::element_blank(),
     strip.text = ggplot2::element_text(
       size = text_size,
       hjust = 0.01
     ),
     panel.grid.minor = ggplot2::element_blank(),
     panel.grid.major = ggplot2::element_blank()
   ) +
   ggplot2::labs(
     caption = "Human presence is detected from pollen data.",
     fill = ""
   ) +
   ggplot2::coord_equal() +
   waffle::geom_waffle(
     mapping = ggplot2::aes(
       fill = status,
       values = N
     ),
     size = 1,
     col = NA,
     n_rows = 15,
     make_proportional = FALSE
   )
```

Now we can apply the selection of best distance to all sequences which fullfil such criteria:
1. Have events
2. Have at least one SPD constructed

We can summary the *best distance* per each continent

```{r}
#| label: best distance region summary data
data_spd_best_dist <-
  targets::tar_read(
    name = "data_spd_best_dist",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

data_to_plot_best_dist <-
   data_meta %>% 
    dplyr::inner_join(
        data_spd_best_dist,
        by = "dataset_id"
    ) 
```

```{r, region_summary-geo, fig.width = 12}
# plot is space
x_lim_dist <-
    range(data_to_plot_best_dist$long)

y_lim_dist <-
    range(data_to_plot_best_dist$lat)

data_to_plot_best_dist %>%
    ggplot2::ggplot(
        ggplot2::aes(long, lat)
    ) +
    ggplot2::borders(fill = "gray95", colour = NA) +
    ggplot2::coord_quickmap(
        ylim = c(min(y_lim_dist), max(y_lim_dist)),
        xlim = c(min(x_lim_dist), max(x_lim_dist))
    ) +
    ggplot2::geom_point(
        ggplot2::aes(
            col = as.factor(best_dist),
            shape = region
        ),
        alpha = 0.75,
        size = 3,
    ) +
    ggplot2::geom_point(
        size = 0.1,
        alpha = 1
    ) +
    ggplot2::scale_size_continuous(
        range = c(0.1, 6)
    ) +
    ggplot2::scale_color_manual(
        values = pallette_dist_vec
    ) +
    ggplot2::guides(
        size = "none",
        shape = "none"
    ) +
    ggplot2::theme(
        legend.position = "bottom"
    ) +
    ggplot2::labs(
        x = "longitude",
        y = "latitude",
        color = "Best distance (km)",
        size = "Best distance (km)",
        subtitle = stringr::str_wrap(
            "Spatial distribution of best distances",
            fig_width_def * 2
        )
    )
```

```{r}
#| label: best distance region summary plot
# calculate summary
data_to_plot_best_dist %>%
    dplyr::group_by(region, best_dist) %>%
    dplyr::count() %>%
    ggplot2::ggplot(
        ggplot2::aes(
            x = as.factor(best_dist),
            y = n
        )
    ) +
    ggplot2::geom_bar(
        ggplot2::aes(
            fill = as.factor(best_dist)
        ),
        size = line_size,
        col = "gray95",
        stat = "identity",
        position = ggplot2::position_dodge(),
    ) +
    ggplot2::facet_wrap(~region, nrow = 1) +
    ggplot2::scale_fill_manual(
        values = pallette_dist_vec
    ) +
    ggplot2::guides(
        fill = "none"
    ) +
    ggplot2::labs(
        y = "Number of sequences",
        x = "Best distance (km)",
        subtitle = stringr::str_wrap(
            "Best distance per each continent",
            fig_width_def * 2
        )
    )
```

# Pollen assemblage properties (PAP) estimation

To prepare the response variables of our main pollen dataset compilation and to be able to analyse fundamental ecosystem properties, we prepared the standard estimates of pollen assemblage properties (PAP) (Bhatta et al. 2023). The PAP estimations provide different aspects of pollen assemblage diversity which includes palynological richness, diversity and evenness, compositional change and turnover, and Rate-of-Change (RoC). 

These response variables are calculated using the newly developed [R-Ecopol package](https://github.com/HOPE-UIB-BIO/R-Ecopol-package) that contain all the functions needed to estimate PAPs for our pollen data assembly. The base functions used in this package are derived from other dependency packages such as `mvpart` package (Therneau et al. 2014) to estimate pollen zonations with multivariate regression trees, `vegan` (Oksanen et al. 2022) for other mutivariate techniques and dissimilarity indices functions from `iNext` (Chao et al. 2014) that have been modified to extract interpolated Hill numbers based on a minimum sample size, and newly developed R functions to run DCCA using `Canoco 4.5` (ter Braak xxxx) to list a few, among other, dependency packages. Additionally, `R-Ratepol` (Mottl 2021) is used get the estimates of RoC  

```{r}
#| label: example site - load pap data
data_prepared_cp <-
  targets::tar_read(
    name = "data_prepared_cp",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

data_pap_example <-
  data_prepared_cp %>%
  dplyr::filter(
    dataset_id == sel_example_record
  ) %>%
    dplyr::select(-dataset_id)
```

## Pollen richness, diversity, and evenness 

The different aspects of palynological diversity are estimated using Hill's effective species numbers N0, N1, N2, and the associated evenness ratios of N2/N1 and N1/N0. These are combined through one equation where the effective species numbers differ mainly in how the rare taxa are weighted in the parameter q:

$$^q{D} = (\sum_{i=1}^{S} p_{i}^{q})^{1/(1-q)}$$

When q is 0, rare and abundant taxa have equal weight and the number is simply the number of taxa in the sample. The equation is not possible to define for q = 1, but as it approaches 1, it is equal to the exponential of the well-known Shannon index and reports the number of equally common taxa. When q = 2, it is the same as the inverse Simpson diversity index and provides the number of equally abundant taxa with a low weight on rare taxa. The advantage of using effective species numbers is that they provide easily interpretable units and contain the doubling effect. To standardize the sample sizes, we use the rarefaction approach developed by Chao et al. These estimates are rarefied to the number of n = 150 grains, or in some cases to a lower sum (minimum n = 25). Some pollen records were only available as pollen percentages, and as the sample size is unknown, these are then rarefied to the minimum sum of percentages. The evenness ratios will be 1 if all taxa are equally abundant, and the ratios hence indicate changes in abundances between the numbers of rare, equally common, and abundant taxa.

We acknowledge that even though attempts are made to standardise richness and diversity estimates based on standard sample size, there are additional biases that are not taken into consideration such as differences in total pollen production and pollen representation (Odgaard 1998, 2001). In some cases, the total pollen sum is also too low to be considered a robust estimate, but it was a choice made on balancing loosing too much information from geographical areas with less data coverage (see data filtering above). 

```{r}
#| label: plot diversity
dplyr::inner_join(
  data_pap_example$PAP_diversity[[1]],
  data_pap_example$levels[[1]],
  by = "sample_id"
) %>%
  dplyr::select(age, dplyr::any_of(
    names(data_pap_example$PAP_diversity[[1]])
  )) %>%
  tidyr::pivot_longer(
    cols = -c(age, sample_id),
    names_to = "var_name",
    values_to = "value"
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = value
    )
  ) +
  ggplot2::facet_wrap(~var_name, nrow = 1, scales = "free_x") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "Pollen diversity",
    x = "age (cal yr BP)",
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()
```

## Compositional change

Compositional change is calculated using multivariate regression trees (MRT) with age as the constraining variable. MRT is in general a robust tool to explore and predict changes in multivariate data sets using environmental predictor variables (De'ath, Simpson and Birks 2012). This technique has been adopted in palaeoecology to detect major zones in pollen diagrams or shifts between periods of homogeneous vegetation in time (Simpson and Birks 2012). We use the pollen taxa in percentages without any data transformations as the response and the median ages derived from the age-depth model as the constraining variable. The recursive partitioning are based on chi-square distances between pollen samples constrained by time. The number of cross-validation is set to 1000, and the optimal sized tree is chosen based on the 1SD rule (Simpson and Birks 2012).  

```{r}
#| label: plot MRT
dplyr::inner_join(
  data_pap_example$mvrt_partitions[[1]],
  data_pap_example$levels[[1]],
  by = "sample_id"
) %>%
  dplyr::select(age, MRT_partitions) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = MRT_partitions
    )
  ) +
  ggplot2::facet_wrap(~"MRT_partitions") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "MVR",
    x = "age (cal yr BP)",
    y = "value"
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()
    
```

## Compositional turnover

Compositional turnover is estimated using detrended canonical correspondence analysis (DCCA) with age as the explanatory variable (ter Braak and Smilauer 2007?). Changes in Weighted average (WA) sample scores (CaseR scores sensu ter Braak and Smilauer 2012) are measures of compositional turnover in standard deviation (SD) units (Birks 2007). The WA scores are regressed with time using a second-order polynomial (age+age\^2) to allow more flexibility in the turnover pattern within a pollen record. Total compositional turnover is a measure of the total length of CaseR scores along the DCCA axis 1, whereas the pattern within a record is the measures between the individual samples along the DCCA axis 1. The response data are pollen percentages without any transformation to maintain the chi-square distances between samples, whereas the ages are the median ages derived from the age-depth model for each site.

```{r}
#| label: plot DCCA1
dplyr::inner_join(
  data_pap_example$dcca_scores[[1]],
  data_pap_example$levels[[1]],
  by = "sample_id"
) %>%
  dplyr::select(age, axis_1) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = axis_1
    )
  ) +
  ggplot2::facet_wrap(~"axis_1") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "DCCA1",
    x = "age (cal yr BP)",
    y = "value"
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()
```

## Rate-of-change

Rate-of-change for the pollen assemblages in the pollen records are quantified using the novel [R-Ratepol package](https://github.com/HOPE-UIB-BIO/R-Ratepol-package) (Mottl et al. 2021). RoC is estimated using moving windows of 500 years' time bins of five number of windows shifts where samples are randomly selected for each bin. This approach is shown to increase the correct detection of RoC peak-points than the more traditional approaches (Mottle et al. 2021). RoC are reported as dissimilarity per 500 years using the Chord dissimilarity coefficient. Sample size is standardized in each working unit to 150 grains or the lowest number detected in each dataset. We use only the RoC scores further in the analyses. 

```{r}
#| label: plot RoC
data_pap_example$PAP_roc[[1]] %>%
  dplyr::select(Age, ROC) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = Age,
      y = ROC
    )
  ) +
  ggplot2::facet_wrap(~"ROC") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "ROC",
    x = "age (cal yr BP)",
    y = "value"
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()
```

## Change-points detection and density estimates

Change-points detection of all the PAP variables are calculated using conventional regression trees (RT) for single variables with Euclidean distances. The transitions between the resulting groups (or zones) per variable is detected and saved as binary (0/1) variables. A change-point is defined as 1, where the mean ages between the two consecutive samples are used as the timing of this significant change. This is done individually for each PAP variable.

The significant change points of the richness, diversity, and evenness variables are combined into one variable, and the significant change points of compositional turnover, compositional change, and rate-of-change is combined in a second variable. The density of these two variables are calculated using a Gaussian kernel,and re-scaled to each of specific age ranges for each individual pollen record (i.e. minimum and maximum ages). To solve the boundary issue in density estimation the data is reflected to 0. We extract the interpolated values at every 500 years time step. 

```{r}
#| label: plot change-points
data_density_estimate <-
  targets::tar_read(
    name = "data_density_estimate",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

data_change_points <-
  targets::tar_read(
    name = "data_change_points",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

data_change_points_example <-
  data_change_points %>%
  dplyr::filter(
    dataset_id == sel_example_record
  )


data_density_estimate %>%
  dplyr::filter(
    dataset_id == sel_example_record
  ) %>%
  purrr::chuck("pap_density_rescale", 1) %>%
  tidyr::pivot_longer(
    cols = c("density_turnover", "density_diversity"),
    names_to = "var_name",
    values_to = "value"
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = value
    )
  ) +
  ggplot2::facet_wrap(~var_name) +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "Density estimates",
    x = "age (cal yr BP)",
  ) +
  ggplot2::geom_segment(
    data = dplyr::bind_rows(
      tibble::tibble(
        age = c(
          data_change_points_example$mvrt_cp[[1]],
          data_change_points_example$dcca_cp[[1]],
          data_change_points_example$roc_cp[[1]]
        ),
        var_name = "density_turnover"
      ),
      tibble::tibble(
        age = data_change_points_example$diversity_cp[[1]]$age,
        var_name = "density_diversity"
      )
    ),
    mapping = ggplot2::aes(
      x = age,
      xend = age,
      y = -Inf,
      yend = Inf
    ),
    col = "gray30",
    alpha = 0.5
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()
```

## Equal spacing of variables

All response variables have been estimated using the harmonised pollen records for each location. To obtain estimates of equal spacing of 500 years, we used linear interpolation. In the context of the temporal analysis we analyse samples distributed in space across time, and equal time steps are necessary.

In order to choose a method of interpolation to obtain data on equal time steps, we compared generalise additive models (GAM), hierarchical generalised additive models (HGAM), and simple linear interpolation. By applying linear interpolation, we found that the correlation structure between the multivariate response variables are more similar to the original estimates without equal spacing than applying a GAM or HGAM. The GAM or HGAM models sometime showed unexpected patterns in single PAP estimate that changed these correlations. Since we cannot individually assess all single models for each of the variable in all of the records (>1000), we choose the simplest linear interpolation method. Similar issues were detected when estimating the density variables of changes points. The first approach was to estimate densities of the individual change points, and then use hierarchical generalised additive models (HGAM) to find the common pattern between the two groups representing significant changes in richness, diversity, and evenness, or change in pollen assemblages (MRT, RoC, DCCA1). As some of the models did not converge and showed inconsistent patterns we use the density estimates on the combined variables directly and extracted the interpolated values at every 500 years step. 

```{r}
#| label: show data for hvar
data_for_hvar <-
  targets::tar_read(
    name = "data_for_hvar",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

pap_vars <-
  c(
    "n0", "n1", "n2",
    "n1_minus_n2", "n2_divided_by_n1",
    "dcca_axis_1", "roc",
    "density_turnover", "density_diversity"
  )

data_for_hvar %>%
  dplyr::filter(
    dataset_id == sel_example_record
  ) %>%
  dplyr::select(-dataset_id) %>%
  tidyr::unnest(data_merge) %>%
  dplyr::select(
    dplyr::all_of(
      c(
        "age",
        pap_vars
      )
    )
  ) %>%
  tidyr::pivot_longer(
    cols = -age,
    names_to = "var_name",
    values_to = "value"
  ) %>%
  dplyr::mutate(
    var_name = factor(
      var_name,
      levels = pap_vars
    )
  )  %>% 
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = value
    )
  ) +
  ggplot2::facet_wrap(~var_name, nrow = 1, scales = "free_x") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "evenly spaced PAP estimates",
    x = "age (cal yr BP)",
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()
```

# Paleo Climate

Paleoclimate from the CHELSA-TraCE21k downscaling algorithm is downloaded from the CHELSA database (Karger et al. 2021, Karger et al. 2021). The selected bioclimatic variables are annual mean temperatures  (bio1, `temp_annual`), minimum temperatures of coldest month  (bio6, `temp_cold`), precipitation of warmest quarter kg m-2 quarter-1 (bio18, `prec_summer`) and precipitation of coldest quarter kg m-2 quarter-1 (bio19, `prec_win`), where we extracted climate values for the coordinates for each dataset_id retrieving the full time series of every 100 years. In addition, we downloaded the monthly climatology for daily maximum near-surface temperature K/10 (tasmin).  

```{r}
#| label: show climate
data_climate <-
  targets::tar_read(
    name = "data_climate",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

climate_vars <-
  c(
    "temp_annual",
    "temp_cold",
    "prec_summer",
    "prec_win"
  )

data_climate %>%
  dplyr::filter(
    dataset_id == sel_example_record
  ) %>%
  purrr::chuck("climate_data", 1) %>%
  tidyr::pivot_longer(
    cols = -age,
    names_to = "var_name",
    values_to = "value"
  ) %>%
  dplyr::filter(
    var_name %in% climate_vars
  ) %>%
  dplyr::mutate(
    var_name = factor(
      var_name,
      levels = climate_vars
    )
  ) %>%
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = value
    )
  ) +
  ggplot2::facet_wrap(~var_name, nrow = 1, scales = "free_x") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "Climate variables for the selected record",
    x = "age (cal yr BP)",
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()

```

# Numerical analysis of hypothesis 1 

## Hierarchical variation partitioning

To test if the ecological processes have changed due to past human activity in single records, we use reduced rank multivariate regression. This is also known as distance-based redundancy analysis (db-RDA). We used the R package `rdacca.hp` to run hierarchial variation partitioning with several predictors. This estimates the variation per variables in different combinations to get the average variable importance independent of the order of predictors. db-RDA was performed using *Gower-distances* adding a constant because our response data, the PAPS, is a mixture of different units. 

Depending on the type of spatial or temporal analysis for hypothesis 1, the explanatory variables are either past human impact (SPDs), palaeoclimatic variables, and/or time (see below). 

SPD is the variable of main interest as it represent past human presence. The palaeoclimate is a matrix of summer precipitation, winter precipitation, annual temperatures, and winter temperatures. These are selected as we considered them most relevant to represent major differences in climatic conditions in all the regions (in respect to differences in warm, cold, dry, wet, or regions with high seasonality). Time is represented by the ages of each pollen record, however, this is more difficult to interpret. We assume age may represent time dependent changes such as natural successions and/or ecological changes due to interaction between taxa.

```{r}
#| label: plot all variables for selected record
data_for_hvar %>%
  dplyr::filter(
    dataset_id == sel_example_record
  ) %>%
  dplyr::select(-dataset_id) %>%
  tidyr::unnest(data_merge) %>%
  tidyr::pivot_longer(
    cols = -age,
    names_to = "var_name",
    values_to = "value"
  ) %>%
  dplyr::mutate(
    var_name = factor(
      var_name,
      levels = c(
        pap_vars,
        "spd",
        climate_vars
      )
  ) 
  ) %>% 
  tidyr::drop_na(var_name) %>% 
  ggplot2::ggplot(
    mapping = ggplot2::aes(
      x = age,
      y = value
    )
  ) +
  ggplot2::facet_wrap(~var_name, nrow = 1, scales = "free_x") +
  ggplot2::coord_flip() +
  ggplot2::scale_x_continuous(
    trans = "reverse"
  ) +
  ggplot2::labs(
    title = "All variables for the selected record",
    x = "age (cal yr BP)",
  ) +
  ggplot2::geom_point() +
  ggplot2::geom_line()    
```


In the hierarchichal variation partitioning analysis, the predictor variables can be applied either as individual predictors or as groups of predictors. In our case, we run the analysis with *groups of predictors*. This means that the palaeoclimatic variables are included as one matrix and not assessed as individual predictors. (The overall results is not very different from using individual predictors). 

The analysis is run in two different ways: 

1. to analyse *spatial changes* which run the hierarchical variation partitioning for single record, then summarise per continent 
2. to analyse the *temporal patterns* in space for each region of the 500 year time steps.

## Spatial changes

We create a single model per each recrods. We then use the adjusted r2 to assess the goodness-of-fit of models. Adjusted r2 is the modified version of r2 that corrects for the number of samples and predictors in the model. It is calculated using the Ezekiel formula adjr2 = 1 - (1- r2)*(n-1)/ (n-m-1), where n = number of samples in the dataset, and m is the number of variables. In vegan, these are so called semipartial r2 (Legendre et al. 2011). Negative adjusted r2 were replaced by 0 in our analysis. The assessment of a satisfactory model fit is contingent upon the underlying data characteristics. Thus, we considered the range of adjusted r2 and removed models with a total fit falling below the 5% lower quantile threshold, specifically those with a total adj r2 below 0.121. 

Then we extracted the total variation of that whole model as well as varience explained by individual predictors. There are three types of variation partition per each predictor: 

- total predictor variation
- shared predictor variation
- unique predictor variation

We then use the total model variation to calculate the percentage of shared and unique variation explained by each predictor.

```{r}
#| label: show example result of hvarpart
output_h1_spatial <-
  targets::tar_read(
    name = "output_hvar_spatial",
    store = paste0(
      data_storage_path,
      "_targets_h1"
    )
  )

data_h1_example <-
  output_h1_spatial %>%
  dplyr::filter(
    dataset_id == "26606"
  ) %>%
  purrr::chuck("varhp", 1)

data_h1_res_example <-
  data_h1_example %>%
  purrr::chuck("summary_table") %>%
  dplyr::mutate(
    total_variance = data_h1_example$varhp_output$Total_explained_variation
  ) %>%
  dplyr::rename(
    p_value = `Pr(>I)`,
    Individual_percent = `I.perc(%)`
  ) %>%
  dplyr::mutate(
    dplyr::across(
      .cols = Unique:Individual_percent,
      .fns = ~ replace(., .x < 0, 0)
    )
  ) %>% # negative variances can be ignored
  dplyr::mutate(
    Individual_percent = Individual / total_variance * 100
  ) %>% # recalculate individual percent
  dplyr::mutate(
    Unique_percent = Unique / total_variance * 100,
    Average.share_percent = Average.share / total_variance * 100
  ) %>%
  janitor::clean_names() %>%
  dplyr::select(
    total_variance,
    predictor,
    predictor_unique = unique,
    predictor_shared = average_share,
    predictor_total = individual,
    predictor_unique_percent = unique_percent,
    predictor_shared_percent = average_share_percent,
    predictor_total_percent = individual_percent
  )


data_h1_res_example %>%
  pander::pandoc.table(
    caption = "Table: Result table of a single record for spatial hierarchichal variation partitioning"
  )
  
  ```

```{r}
#| label: h1 spatial visulalisation
data_h1_res_example  %>% 
dplyr::select(
  predictor, predictor_unique_percent, predictor_shared_percent
)  %>% 
tidyr::pivot_longer(
  cols = -predictor
)  %>% 
ggplot2::ggplot(
  mapping = ggplot2::aes(
    x = predictor,
    y = value,
    fill = predictor,
    alpha = name
  )
) +
ggplot2::scale_y_continuous(
  limits = c(0, 100),
) +
ggplot2::scale_alpha_discrete(
  "shared/unique",
  range = c(0.5, 1),
  labels = c("shared", "unique")
) +
ggplot2::guides(
  fill = "none",
) +
ggplot2::labs(
  y = "percent of variance explained by predictor",
)+
ggplot2::geom_col(
  position = ggplot2::position_dodge(
    width = 0.9
  )
) 

```

However, for certain records, the shared variance of predictors is much larger than the total variance of the model. This caused percentages to be very high.

```{r}
#| label: show bad example result of hvarpart
data_h1_example_bad <-
  output_h1_spatial %>%
  dplyr::filter(
    dataset_id == sel_example_record
  ) %>%
  purrr::chuck("varhp", 1)

data_h1_res_example_bad <-
  data_h1_example_bad %>%
  purrr::chuck("summary_table") %>%
  dplyr::mutate(
    total_variance = data_h1_example_bad$varhp_output$Total_explained_variation
  ) %>%
  dplyr::rename(
    p_value = `Pr(>I)`,
    Individual_percent = `I.perc(%)`
  ) %>%
  dplyr::mutate(
    dplyr::across(
      .cols = Unique:Individual_percent,
      .fns = ~ replace(., .x < 0, 0)
    )
  ) %>% # negative variances can be ignored
  dplyr::mutate(
    Individual_percent = Individual / total_variance * 100
  ) %>% # recalculate individual percent
  dplyr::mutate(
    Unique_percent = Unique / total_variance * 100,
    Average.share_percent = Average.share / total_variance * 100
  ) %>%
  janitor::clean_names() %>%
  dplyr::select(
    total_variance,
    predictor,
    predictor_unique = unique,
    predictor_shared = average_share,
    predictor_total = individual,
    predictor_unique_percent = unique_percent,
    predictor_shared_percent = average_share_percent,
    predictor_total_percent = individual_percent
  )


data_h1_res_example_bad %>%
  pander::pandoc.table(
    caption = "Table: Result table of a single record for spatial hierarchichal variation partitioning"
  )

```

In these cases, the outliers above 100% were removed. 

### Summary across climate zone per continent

We then summarised the results per each climate zone within continent.

Here is an example of the distribution of uniqu varience explained by humans for Europe (part of Figure 3).

```{r}
#| label: plot unique human impact in Europe

# Import tables for plotting
source(
  here::here(
    "R/working_scripts/Results_script.R"
  )
)


data_unique_human <-
  data_spatial_vis %>%
  dplyr::mutate(
    sel_classification = as.factor(sel_classification),
    region = factor(region,
      levels = vec_regions
    )
  ) %>%
  dplyr::full_join(
    data_climate_zones, # [config criteria]
    .,
    by = "sel_classification"
  ) %>%
  dplyr::filter(
    predictor == "human"
  ) %>%
  dplyr::group_by(region) %>%
  tidyr::nest(
    data_to_plot = -c(region)
  ) %>%
  dplyr::ungroup()


get_unique_human_dist <- function(
    data_source,
    sel_region,
    point_size = 3) {
  data_work <-
    data_source %>%
    dplyr::mutate(sel_classification = as.factor(sel_classification)) %>%
    dplyr::full_join(
      data_climate_zones, # [config criteria]
      .,
      by = "sel_classification"
    )

  data_work %>%
    ggplot2::ggplot(
      mapping = ggplot2::aes(
        x = 1,
        y = unique_percent
      )
    ) +
    ggplot2::facet_wrap(~sel_classification, nrow = 1) +
    ggplot2::scale_y_continuous(
      limits = c(0, 100)
    ) +
    ggplot2::scale_fill_manual(
      values = palette_ecozones # [config criteria]
    ) +
    ggplot2::scale_color_manual(
      values = palette_ecozones # [config criteria]
    ) +
    ggplot2::theme_bw() +
    ggplot2::theme(
      text = ggplot2::element_text(
        size = text_size # [config criteria]
      ),
      line = ggplot2::element_line(
        linewidth = line_size # [config criteria]
      ),
      legend.position = "none",
      panel.spacing.x = grid::unit(0, "mm"),
      panel.border = ggplot2::element_blank(),
      strip.background = ggplot2::element_blank(),
      strip.text = ggplot2::element_blank(),
      axis.text.x = ggplot2::element_blank(),
      axis.ticks.x = ggplot2::element_blank(),
      panel.grid.minor = ggplot2::element_blank(),
      panel.grid.major.x = ggplot2::element_blank(),
      plot.margin = grid::unit(c(0.1, 0.1, 0.1, 0.1), "mm")
    ) +
    ggplot2::labs(
      x = "Climate zone",
      y = "Unique variance explained by human impact (%)"
    ) +
    ggplot2::geom_jitter(
      mapping = ggplot2::aes(
        col = sel_classification
      ),
      alpha = 0.3
    ) +
    ggplot2::geom_violin(
      mapping = ggplot2::aes(
        fill = sel_classification
      ),
      alpha = 0.3,
      col = NA
    ) +
    ggplot2::geom_boxplot(
      fill = "white",
      col = "grey30",
      width = 0.1,
      outlier.shape = NA
    ) +
    ggplot2::geom_point(
      data = data_work %>%
        dplyr::group_by(sel_classification) %>%
        dplyr::summarise(
          unique_percent = median(unique_percent)
        ),
      mapping = ggplot2::aes(
        fill = sel_classification
      ),
      shape = 22,
      col = "gray30",
      size = point_size
    )
}

data_fig_unique_human_dist <-
  data_unique_human %>%
  dplyr::mutate(
    plot = purrr::map(
      .x = data_to_plot,
      .f = ~ get_unique_human_dist(
        data_source = .x
      )
    )
  )

data_fig_unique_human_dist  %>% 
dplyr::filter(
  region == "Europe"
)  %>% 
purrr::chuck("plot", 1) +
ggplot2::labs(
  title = "Europe",
  x = "Climate zone",
  y = "Unique variance explained by human impact (%)"
) 



```

We then estimate the the median value of variance explained by each predictor (unique and shared).

```{r}
#| label: h1 summary per continent
  summary_spatial_median %>%
  dplyr::mutate(
    sel_classification = factor(sel_classification)
  ) %>%
  dplyr::mutate(
    predictor = factor(
      predictor,
      levels = predictors_spatial_order # [config criteria]
    )
  ) %>%
  dplyr::filter(n_records > 5)  %>% 
dplyr::filter(
  region == "Europe"
)   %>% 
get_circular_barplot() +
ggplot2::labs(
  title = "Europe"
)

```

## Temporal changes

In this latter analysis, we restructure the data so that each analysis is run per time bin for each continent. First we did it for each ecozone on a continent, but the results is relatively similar so we use the continental scale. The predictor groups in each time bin are the past human presence and the matrix of palaeoclimatic variables. It was necessary to filter out time bins which have less than 5 samples, and for some bins, if all the spds equal zero, the analysis will fail. In this cases there is an insufficient numbers of predictors and the analysis will return NA for these specific time bins.

